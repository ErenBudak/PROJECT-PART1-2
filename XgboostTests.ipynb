{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "74dc5f3f",
   "metadata": {},
   "source": [
    "DATASET1 XGBOOST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c4f75f3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 26244 candidates, totalling 78732 fits\n",
      "Dataset 1 XGBoost Sonuçları:\n",
      "   Magnitude   : MSE=0.058, MAE=0.217, R²=-5.052\n",
      "   Depth       : MSE=14.691, MAE=3.054, R²=-1.431\n",
      "   Latitude    : MSE=1.559, MAE=0.982, R²=-0.012\n",
      "   Longitude   : MSE=18.600, MAE=3.145, R²=-0.013\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eren1\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import GridSearchCV, TimeSeriesSplit\n",
    "%run MLProject.ipynb\n",
    "df = pd.read_csv('usgs_main.csv')\n",
    "df1 = df.copy()\n",
    "df1['time'] = pd.to_datetime(df1['time'])\n",
    "df1 = df1.sort_values('time')\n",
    "df1 = df1.dropna(subset=['latitude','longitude','depth','mag','time'])\n",
    "\n",
    "dfweek_xgb = df1.set_index('time').resample('W').apply({\n",
    "    'mag':'mean',\n",
    "    'latitude':'mean',\n",
    "    'longitude':'mean',\n",
    "    'depth':'mean',    #magType type vesairenin düzenlenmesinde yapay zekadan yararlandım\n",
    "    'magType': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'type': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'status': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0],\n",
    "    'net': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 else x.iloc[0]\n",
    "})\n",
    "\n",
    "dfweek_xgb = dfweek_xgb.reset_index(drop=True)\n",
    "dfweek_xgb.index = dfweek_xgb.index + 1\n",
    "dfweek_xgb.index.name = 'timeindex'\n",
    "\n",
    "dfweek_xgb['futuremag'] = dfweek_xgb['mag'].shift(-1)\n",
    "dfweek_xgb['futuredepth'] = dfweek_xgb['depth'].shift(-1)\n",
    "dfweek_xgb['futurelat'] = dfweek_xgb['latitude'].shift(-1)\n",
    "dfweek_xgb['futurelon'] = dfweek_xgb['longitude'].shift(-1)\n",
    "dfweek_xgb = dfweek_xgb.dropna(subset=['futuremag','futuredepth','futurelat','futurelon'])\n",
    "\n",
    "xgb_hiperparametreler = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [3, 5, 7, 9],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'subsample': [0.8, 0.9, 1.0],\n",
    "    'colsample_bytree': [0.8, 0.9, 1.0],\n",
    "    'min_child_weight': [1, 3, 5],\n",
    "    'reg_alpha': [0, 0.1, 0.5],\n",
    "    'reg_lambda': [1, 1.5, 2],\n",
    "    'shiftnum': [2, 3, 4]\n",
    "}\n",
    "\n",
    "train_xgb = dfweek_xgb[:int((4*len(dfweek_xgb))/5)]\n",
    "test_xgb = dfweek_xgb[int(4*len(dfweek_xgb)/5):]\n",
    "\n",
    "splitter_xgb = TimeSeriesSplit(n_splits=3)\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=XGBoostEarthquakePredictor(random_state=42),\n",
    "    param_grid=xgb_hiperparametreler,\n",
    "    cv=splitter_xgb,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_xgb.fit(train_xgb)\n",
    "best_model_xgb = grid_xgb.best_estimator_\n",
    "\n",
    "test_predictions_xgb = best_model_xgb.predict(test_xgb)\n",
    "test_actual_xgb = test_xgb[['futuremag', 'futuredepth', 'futurelat', 'futurelon']].dropna()\n",
    "min_len_xgb = min(len(test_predictions_xgb), len(test_actual_xgb))\n",
    "\n",
    "target_names = ['futuremag', 'futuredepth', 'futurelat', 'futurelon']\n",
    "target_labels = ['Magnitude', 'Depth', 'Latitude', 'Longitude']\n",
    "\n",
    "print(\"Dataset 1 XGBoost Sonuçları:\")  #buradaki sonuç yazdırma kısmında yapay zekadan benim için mse mae r2 testlerini yazdırmasını istedim\n",
    "for i, (name, label) in enumerate(zip(target_names, target_labels)):\n",
    "    if i < test_predictions_xgb.shape[1] and i < test_actual_xgb.shape[1]:\n",
    "        target_mse = mean_squared_error(\n",
    "            test_actual_xgb.iloc[:min_len_xgb, i], \n",
    "            test_predictions_xgb[:min_len_xgb, i]\n",
    "        )\n",
    "        target_mae = mean_absolute_error(\n",
    "            test_actual_xgb.iloc[:min_len_xgb, i], \n",
    "            test_predictions_xgb[:min_len_xgb, i]\n",
    "        )\n",
    "        target_r2 = r2_score(\n",
    "            test_actual_xgb.iloc[:min_len_xgb, i], \n",
    "            test_predictions_xgb[:min_len_xgb, i]\n",
    "        )\n",
    "        \n",
    "        print(f\"   {label:12}: MSE={target_mse:.3f}, MAE={target_mae:.3f}, R²={target_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fce335",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.8, 'learning_rate': 0.01, 'max_depth': 3, 'min_child_weight': 1, 'n_estimators': 100, 'reg_alpha': 0, 'reg_lambda': 1, 'shiftnum': 2, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "import json   #joblib ve json ile işlem için yapay zeka yardımına başvurdum\n",
    "joblib.dump(best_model_xgb, 'models/xgboost_dataset1.pkl')\n",
    "xgb_best_params = {\n",
    "    'dataset1_params': grid_xgb.best_params_\n",
    "}\n",
    "print(grid_xgb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cba96314",
   "metadata": {},
   "source": [
    "XGBOOST DATASET 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "182aa1cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 26244 candidates, totalling 78732 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\eren1\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1108: UserWarning: One or more of the test scores are non-finite: [nan nan nan ... nan nan nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Magnitude   : MSE=0.001, MAE=0.022, R²=-1.111\n",
      "   Depth       : MSE=155.373, MAE=10.910, R²=-0.377\n",
      "   Latitude    : MSE=16.833, MAE=3.190, R²=-0.443\n",
      "   Longitude   : MSE=202.669, MAE=11.954, R²=-0.145\n"
     ]
    }
   ],
   "source": [
    "pn = pd.read_csv('Significant Earthquake Dataset 1900-2023.csv')\n",
    "df2 = pn.copy()\n",
    "df2 = df2.rename(columns={\n",
    "    'Time':'time', 'Mag':'mag', 'Depth':'depth', \n",
    "    'Latitude':'latitude', 'Longitude':'longitude'\n",
    "})\n",
    "\n",
    "df2['time'] = pd.to_datetime(df2['time'])\n",
    "df2 = df2.sort_values('time')\n",
    "df2 = df2.dropna(subset=['latitude','longitude','depth','mag','time'])\n",
    "\n",
    "\n",
    "dfyear_xgb = df2.set_index('time').resample('YE').apply({\n",
    "    'mag':'mean',\n",
    "    'latitude':'mean',\n",
    "    'longitude':'mean',\n",
    "    'depth':'mean',  #Yapay zekadan 1. datasette one hot encode verileri için yardım almıştım,burada da aynı yöntemi kullandım\n",
    "    'MagType': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and len(x) > 0 else 'Unknown',\n",
    "    'Type': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and len(x) > 0 else 'Unknown',\n",
    "    'status': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and len(x) > 0 else 'Unknown',\n",
    "    'net': lambda x: x.mode().iloc[0] if len(x.mode()) > 0 and len(x) > 0 else 'Unknown'\n",
    "})\n",
    "\n",
    "# Label uyuşmazlığı hatası alınca ekledim\n",
    "dfyear_xgb = dfyear_xgb.rename(columns={'MagType':'magType','Type':'type'})\n",
    "\n",
    "dfyear_xgb = dfyear_xgb.reset_index(drop=True)\n",
    "dfyear_xgb.index = dfyear_xgb.index + 1\n",
    "dfyear_xgb.index.name = 'timeindex'\n",
    "\n",
    "dfyear_xgb['futuremag'] = dfyear_xgb['mag'].shift(-1)\n",
    "dfyear_xgb['futuredepth'] = dfyear_xgb['depth'].shift(-1)\n",
    "dfyear_xgb['futurelat'] = dfyear_xgb['latitude'].shift(-1)\n",
    "dfyear_xgb['futurelon'] = dfyear_xgb['longitude'].shift(-1)\n",
    "dfyear_xgb = dfyear_xgb.dropna(subset=['futuremag','futuredepth','futurelat','futurelon'])\n",
    "\n",
    "xgb_hiperparametreler_2 = {\n",
    "    'n_estimators': [200,320,400],\n",
    "    'max_depth': [4,6,8,10],\n",
    "    'learning_rate': [0.05,0.11,0.15],\n",
    "    'subsample': [0.7,0.8,0.9],\n",
    "    'colsample_bytree': [0.7,0.8,0.9],\n",
    "    'min_child_weight': [1,2,3],\n",
    "    'reg_alpha': [0,0.1,0.3],\n",
    "    'reg_lambda': [1,1.3,1.5],\n",
    "    'shiftnum': [3,4,5]\n",
    "}\n",
    "\n",
    "train_xgb_2 = dfyear_xgb[:int((4*len(dfyear_xgb))/5)]\n",
    "test_xgb_2 = dfyear_xgb[int(4*len(dfyear_xgb)/5):]\n",
    "\n",
    "splitter_xgb_2 = TimeSeriesSplit(n_splits=3)\n",
    "grid_xgb_2 = GridSearchCV(\n",
    "    estimator=XGBoostEarthquakePredictor(random_state=42),\n",
    "    param_grid=xgb_hiperparametreler_2,\n",
    "    cv=splitter_xgb_2,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "grid_xgb_2.fit(train_xgb_2)\n",
    "\n",
    "best_model_xgb_2 = grid_xgb_2.best_estimator_\n",
    "\n",
    "test_predictions_xgb_2 = best_model_xgb_2.predict(test_xgb_2)\n",
    "test_actual_xgb_2 = test_xgb_2[['futuremag', 'futuredepth', 'futurelat', 'futurelon']].dropna()\n",
    "min_len_xgb_2 = min(len(test_predictions_xgb_2), len(test_actual_xgb_2))\n",
    "\n",
    "\n",
    "target_names = ['futuremag', 'futuredepth', 'futurelat', 'futurelon']\n",
    "target_labels = ['Magnitude', 'Depth', 'Latitude', 'Longitude']\n",
    "\n",
    "#Yine dataset 1 deki gibi sonuç yazdığımız kısım,aynı şekilde kullandım,sadece değişken isimleri farklı\n",
    "for i, (name, label) in enumerate(zip(target_names, target_labels)):\n",
    "    if i < test_predictions_xgb_2.shape[1] and i < test_actual_xgb_2.shape[1]:\n",
    "        target_mse = mean_squared_error(\n",
    "            test_actual_xgb_2.iloc[:min_len_xgb_2, i], \n",
    "            test_predictions_xgb_2[:min_len_xgb_2, i]\n",
    "        )\n",
    "        target_mae = mean_absolute_error(\n",
    "            test_actual_xgb_2.iloc[:min_len_xgb_2, i], \n",
    "            test_predictions_xgb_2[:min_len_xgb_2, i]\n",
    "        )\n",
    "        target_r2 = r2_score(\n",
    "            test_actual_xgb_2.iloc[:min_len_xgb_2, i], \n",
    "            test_predictions_xgb_2[:min_len_xgb_2, i]\n",
    "        )\n",
    "        \n",
    "        print(f\"   {label:12}: MSE={target_mse:.3f}, MAE={target_mae:.3f}, R²={target_r2:.3f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5f884a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'colsample_bytree': 0.7, 'learning_rate': 0.05, 'max_depth': 4, 'min_child_weight': 1, 'n_estimators': 200, 'reg_alpha': 0, 'reg_lambda': 1, 'shiftnum': 3, 'subsample': 0.7}\n"
     ]
    }
   ],
   "source": [
    "joblib.dump(best_model_xgb_2, 'models/xgboost_dataset2.pkl')\n",
    "xgb_best_params['dataset2_params'] = grid_xgb_2.best_params_\n",
    "print(grid_xgb_2.best_params_)\n",
    "with open('models/xgboost_best_params.json', 'w') as f:\n",
    "    json.dump(xgb_best_params, f, indent=2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
